# ==============================================================================
# ğŸ“ ì‚¬ì „ ì¤€ë¹„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° API í‚¤ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
# ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰: !pip install google-generativeai pandas
import google.generativeai as genai
import pandas as pd
import json
import os
import time
import re

PATH = './09_dongwon/'
os.makedirs(PATH, exist_ok=True)

# [ì¤‘ìš”] ì‚¬ìš©ìì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
try:
    # -------------------------------------------------------------------------
    genai.configure(api_key="AIzaSyApXG30wdefn3AwnlnyZVVK0zdfMmzVHPA") # <--- ì—¬ê¸°ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    # -------------------------------------------------------------------------
    print("âœ… Gemini API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"â—ï¸ API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ==============================================================================
# ğŸ¤– 1ë‹¨ê³„: ë²”ìš© í˜ë¥´ì†Œë‚˜ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì •ì˜ (âœ¨ ê°„ì†Œí™” ë²„ì „)
# ==============================================================================
PROMPT_FOR_PERSONAS = """
ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¥ì˜ ì†Œë¹„ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ë§ˆì¼€íŒ… ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤.

[ì§€ì‹œì‚¬í•­]
1.  **ì„ë¬´**: '2024ë…„ ëŒ€í•œë¯¼êµ­ ì†Œë¹„ì'ë¥¼ ëŒ€í‘œí•˜ëŠ” ê°€ìƒ í˜ë¥´ì†Œë‚˜ 30ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
2.  **ì¡°ê±´**:
    * ìƒì„±ë˜ëŠ” í˜ë¥´ì†Œë‚˜ì˜ ì¸êµ¬í†µê³„í•™ì  ë¶„í¬ëŠ” ì‹¤ì œ ëŒ€í•œë¯¼êµ­ í†µê³„ì™€ ìœ ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.
    * `[ì†ì„± ê°€ì´ë“œ]`ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ì–‘í•œ ì†ì„±ì„ ì¡°í•©í•˜ë˜, ê° í˜ë¥´ì†Œë‚˜ì˜ ì†ì„±ê³¼ êµ¬ë§¤ í–‰ë™(í™•ë¥ /ë¹ˆë„)ì€ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
3.  **ì¶œë ¥**: ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ `[ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]`ë¥¼ ì™„ë²½íˆ ë”°ë¥´ëŠ” ë‹¨ì¼ JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”.

[ì†ì„± ê°€ì´ë“œ]
-   `age`: "10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"
-   `gender`: "ë‚¨ì„±", "ì—¬ì„±"
-   `occupation`: "ì§ì¥ì¸", "í•™ìƒ", "ì£¼ë¶€", "í”„ë¦¬ëœì„œ", "ìì˜ì—…ì", "ë¬´ì§", "ì€í‡´"
-   `income_level`: "ìƒ", "ì¤‘ìƒ", "ì¤‘", "ì¤‘í•˜", "í•˜"
-   `household_size`: "1ì¸ ê°€êµ¬", "2ì¸ ê°€êµ¬", "3ì¸ ê°€êµ¬", "4ì¸ ê°€êµ¬ ì´ìƒ"
-   `lifestyle`: "ê±´ê°•ì§€í–¥", "ìê¸°ê´€ë¦¬", "í¸ì˜ì„±ì¶”êµ¬", "ê°€ì„±ë¹„ì¤‘ì‹œ", "íŠ¸ë Œë“œì¶”êµ¬", "ìš”ë¦¬ì• í˜¸ê°€", "ì§‘ë°¥ì„ í˜¸", "ë¯¸ì‹ê°€"
-   `media_consumption`: "TV", "YouTube", "Instagram", "Facebook", "ë„¤ì´ë²„ë‰´ìŠ¤", "ì»¤ë®¤ë‹ˆí‹°ì‚¬ì´íŠ¸" (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)
-   `price_sensitivity`: "ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ"
-   `brand_loyalty`: "ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ"
-   `dietary_preferences`: "ê³ ë‹¨ë°±", "ì €ì¹¼ë¡œë¦¬", "ìœ ë‹¹ë¶ˆë‚´ì¦ì¼€ì–´", "ì†Œí™”í¸í•œìŒì‹ì„ í˜¸", "ë§¤ìš´ë§›ì„ í˜¸", "í•´ì‚°ë¬¼ì„ í˜¸", "í•´ë‹¹ì—†ìŒ"
-   `shopping_channel`: "ëŒ€í˜•ë§ˆíŠ¸", "ì˜¨ë¼ì¸", "í¸ì˜ì ", "ë°±í™”ì ", "ì „í†µì‹œì¥"

[ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
[
  {
    "persona_id": "P00001",
    "attributes": {
      "age": "30ëŒ€",
      "gender": "ì—¬ì„±",
      "occupation": "ì§ì¥ì¸",
      "income_level": "ì¤‘ìƒ",
      "household_size": "1ì¸ ê°€êµ¬",
      "lifestyle": "ê±´ê°•ì§€í–¥",
      "media_consumption": ["YouTube", "Instagram"],
      "price_sensitivity": "ì¤‘ê°„",
      "brand_loyalty": "ë‚®ìŒ",
      "dietary_preferences": "ê³ ë‹¨ë°±",
      "shopping_channel": "ì˜¨ë¼ì¸"
    },
    "purchase_probability": 0.75,
    "base_purchase_frequency_per_month": 3.0,
    "monthly_propensity_modifier": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
  }
]
"""
print("âœ… 1ë‹¨ê³„: [ê°„ì†Œí™”] í•µì‹¬ ì§€ì‹œì‚¬í•­ì„ ë‹´ì€ í˜ë¥´ì†Œë‚˜ ìƒì„± í”„ë¡¬í”„íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ==============================================================================
# ğŸ“¥ 2ë‹¨ê³„: Gemini API í˜¸ì¶œ ë° í˜ë¥´ì†Œë‚˜ ë°ì´í„° ìƒì„± (âœ¨ ì•ˆì •ì„± ë° ë°ì´í„° í’ˆì§ˆ ëŒ€í­ ê°œì„ )
# ==============================================================================

def extract_json_from_response(text):
    """ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•´ ëª¨ë¸ ì‘ë‹µì—ì„œ JSON ë°°ì—´ ë¶€ë¶„ë§Œ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # ê°€ì¥ ë¨¼ì € ë‚˜ì˜¤ëŠ” '[' ì™€ ê°€ì¥ ë§ˆì§€ë§‰ì— ë‚˜ì˜¤ëŠ” ']' ì‚¬ì´ì˜ ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤.
    match = re.search(r'\[.*\]', text, re.DOTALL)
    if match:
        return match.group(0)
    return None

def validate_persona(persona_dict):
    """ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ ê°ì²´ì— í•„ìˆ˜ í‚¤ê°€ ëª¨ë‘ ìˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤."""
    required_keys = ['persona_id', 'attributes', 'purchase_probability', 'base_purchase_frequency_per_month']
    return all(key in persona_dict for key in required_keys)


persona_filename = os.path.join(PATH, 'personas_2_3000.json')
total_personas_to_generate = 3000
batch_size = 30
num_batches = total_personas_to_generate // batch_size
max_retries_per_batch = 5 # ë°°ì¹˜ ë‹¹ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

if not os.path.exists(persona_filename):
    print(f"\nâ³ 2ë‹¨ê³„: ì´ {total_personas_to_generate}ê°œì˜ í˜ë¥´ì†Œë‚˜ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤ ({batch_size}ê°œì”© {num_batches}íšŒ).")
    all_personas = []
    model = genai.GenerativeModel('models/gemini-2.0-flash')

    for i in range(num_batches):
        current_batch_success = False
        for attempt in range(max_retries_per_batch):
            print(f"  - ë°°ì¹˜ {i+1}/{num_batches} ìƒì„± ì¤‘... (ì‹œë„ {attempt+1}/{max_retries_per_batch})")
            try:
                response = model.generate_content(PROMPT_FOR_PERSONAS)
                
                # 1. ì§€ëŠ¥ì ì¸ JSON ì¶”ì¶œ
                json_text = extract_json_from_response(response.text)
                if not json_text:
                    raise ValueError("ì‘ë‹µì—ì„œ JSON ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                batch_personas = json.loads(json_text)

                # 2. ë°ì´í„° ê²€ì¦
                if not all(validate_persona(p) for p in batch_personas):
                    raise ValueError("ì¼ë¶€ í˜ë¥´ì†Œë‚˜ì— í•„ìˆ˜ í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

                all_personas.extend(batch_personas)
                print(f"  âœ… ë°°ì¹˜ {i+1} ìƒì„± ì™„ë£Œ! (í˜„ì¬ {len(all_personas)}ê°œ)")
                current_batch_success = True
                break # í˜„ì¬ ë°°ì¹˜ ì„±ê³µ ì‹œ, ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ

            except Exception as e:
                print(f"  â—ï¸ ë°°ì¹˜ {i+1} ì‹œë„ {attempt+1} ì‹¤íŒ¨: {e}")
                if attempt < max_retries_per_batch - 1:
                    print("  15ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                    time.sleep(15)
                else:
                    print(f"  âŒ ë°°ì¹˜ {i+1} ìƒì„± ìµœì¢… ì‹¤íŒ¨. ë‹¤ìŒ ë°°ì¹˜ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
        
        # 3. API í• ë‹¹ëŸ‰ ì¤€ìˆ˜ë¥¼ ìœ„í•œ ëŒ€ê¸°
        if i < num_batches - 1:
            print("  ğŸ•’ API í• ë‹¹ëŸ‰ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 60ì´ˆê°„ ëŒ€ê¸°í•©ë‹ˆë‹¤...")
            time.sleep(60)

    # ìµœì¢… ID ì¬ì„¤ì •
    for i, p in enumerate(all_personas):
        p['persona_id'] = f"P{i+1:05d}"
            
    with open(persona_filename, 'w', encoding='utf-8') as f:
        json.dump(all_personas, f, ensure_ascii=False, indent=2)
    print(f"âœ… ì„±ê³µ! ì´ {len(all_personas)}ê°œì˜ í˜ë¥´ì†Œë‚˜ë¥¼ '{persona_filename}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
else:
    print(f"\nâœ… 2ë‹¨ê³„: '{persona_filename}' íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ API í˜¸ì¶œì„ ìƒëµí•©ë‹ˆë‹¤.")

# ==============================================================================
# ğŸ“‚ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
try:
    personas_df = pd.read_json(persona_filename)
    attributes_df = pd.json_normalize(personas_df['attributes'])
    personas_df = pd.concat([personas_df.drop('attributes', axis=1), attributes_df], axis=1)
    # product_info.csvëŠ” ì´ì œ SIMULATION_PARAMSë¡œ ëŒ€ì²´ë˜ë¯€ë¡œ ë¡œë“œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
    submission_df = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))
    print("\nâœ… ëª¨ë“  ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
except FileNotFoundError as e:
    print(f"â—ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}. í•„ìš”í•œ íŒŒì¼ë“¤ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ==============================================================================
# ğŸ”¬ 3ë‹¨ê³„: ì œí’ˆë³„ ê³ ê° ì„¸ë¶„í™” ë° ê°€ì¤‘ì¹˜ ë¶€ì—¬ í•¨ìˆ˜ ì •ì˜ (âœ¨ ëŒ€í­ ê³ ë„í™”ë¨)
# ==============================================================================
def get_weights_by_product(product_name, df):
    weights = pd.Series(1.0, index=df.index)
    
    # ------------------- [ 1. ì œí’ˆêµ°ë³„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ ë¶€ì—¬ (ê¸°ì¡´ ë¡œì§) ] -------------------
    if 'í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸' in product_name:
        primary_mask = df['age'].isin(['20ëŒ€', '30ëŒ€', '40ëŒ€']) & df['lifestyle'].isin(['ê±´ê°•ì§€í–¥', 'ìê¸°ê´€ë¦¬'])
        weights[primary_mask] *= 2.0 # ê¸°ì¡´ ê°€ì¤‘ì¹˜ì— ê³±í•˜ëŠ” ë°©ì‹(*=)ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì¤‘ì²© ì ìš©
        secondary_mask = (df['household_size'] == '1ì¸ ê°€êµ¬') | (df['income_level'].isin(['ì¤‘ìƒ', 'ìƒ']))
        weights[secondary_mask & ~primary_mask] *= 1.5
        
    elif 'ë§›ì°¸' in product_name:
        primary_mask = df['age'].isin(['10ëŒ€', '20ëŒ€', '30ëŒ€']) & df['media_consumption'].apply(lambda x: isinstance(x, list) and ('YouTube' in x or 'Instagram' in x))
        primary_mask &= df['shopping_channel'].isin(['í¸ì˜ì ', 'ì˜¨ë¼ì¸'])
        weights[primary_mask] *= 2.5
        secondary_mask = (df['household_size'] == '1ì¸ ê°€êµ¬') & (df['lifestyle'] == 'í¸ì˜ì„±ì¶”êµ¬')
        weights[secondary_mask & ~primary_mask] *= 1.8

    elif 'ë¦¬ì±”' in product_name:
        primary_mask = df['age'].isin(['30ëŒ€', '40ëŒ€']) & df['occupation'].isin(['ì£¼ë¶€', 'ì „ì—…ì£¼ë¶€']) & (df['household_size'] != '1ì¸ ê°€êµ¬')
        primary_mask &= df['shopping_channel'].isin(['ëŒ€í˜•ë§ˆíŠ¸'])
        weights[primary_mask] *= 2.0

    elif 'ì°¸ì¹˜ì•¡' in product_name:
        primary_mask = df['age'].isin(['30ëŒ€', '40ëŒ€', '50ëŒ€']) & df['occupation'].isin(['ì£¼ë¶€', 'ì „ì—…ì£¼ë¶€'])
        primary_mask &= df['shopping_channel'].isin(['ëŒ€í˜•ë§ˆíŠ¸', 'ì˜¨ë¼ì¸'])
        weights[primary_mask] *= 2.2
        secondary_mask = (df['household_size'] == '1ì¸ ê°€êµ¬') & df['lifestyle'].isin(['ìš”ë¦¬ì• í˜¸ê°€', 'ì§‘ë°¥ì„ í˜¸'])
        weights[secondary_mask & ~primary_mask] *= 1.7

    elif 'ì†Œí™”ê°€ ì˜ë˜ëŠ”' in product_name:
        primary_mask = df['age'].isin(['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€']) & df['dietary_preferences'].isin(['ìœ ë‹¹ë¶ˆë‚´ì¦ì¼€ì–´', 'ì†Œí™”í¸í•œìŒì‹ì„ í˜¸'])
        primary_mask &= df['shopping_channel'].isin(['í¸ì˜ì '])
        weights[primary_mask] *= 2.8
        secondary_mask = df['occupation'].isin(['ì§ì¥ì¸']) & df['lifestyle'].isin(['ê±´ê°•ì§€í–¥'])
        weights[secondary_mask & ~primary_mask] *= 1.5

    # ------------------- [ 2. ìš©ëŸ‰/ë§›/íŠ¹ì„±ë³„ ìƒì„¸ ê°€ì¤‘ì¹˜ ì¶”ê°€ ë¶€ì—¬ ] -------------------
    # [ê°€ì„¤ 1] ê°€êµ¬ ê·œëª¨ì— ë”°ë¥¸ ìš©ëŸ‰ ì„ í˜¸ë„
    # - 1ì¸ ê°€êµ¬: ì†Œìš©ëŸ‰ ì„ í˜¸ (+20%), ëŒ€ìš©ëŸ‰ ê¸°í”¼ (-10%)
    # - ë‹¤ì¸ ê°€êµ¬: ëŒ€ìš©ëŸ‰ ì„ í˜¸ (+20%), ì†Œìš©ëŸ‰ ê¸°í”¼ (-10%)
    is_large_capacity = any(x in product_name for x in ['400g', '900g', '340g'])
    is_small_capacity = any(x in product_name for x in ['90g', '135g', '200g', '500g']) # 500gëŠ” ì¤‘ê°„ì´ì§€ë§Œ ì—¬ê¸°ì„  ì‘ì€í¸ìœ¼ë¡œ ë¶„ë¥˜
    
    single_household_mask = df['household_size'] == '1ì¸ ê°€êµ¬'
    multi_household_mask = df['household_size'] != '1ì¸ ê°€êµ¬'

    if is_large_capacity:
        weights[single_household_mask] *= 0.9
        weights[multi_household_mask] *= 1.2
    elif is_small_capacity:
        weights[single_household_mask] *= 1.2
        weights[multi_household_mask] *= 0.9

    # [ê°€ì„¤ 2] ë§›(ë§¤ìš´ë§›/ì§„í•œë§›) ì„ í˜¸ë„
    # - ë§¤ìš´ë§›: ì Šì€ ì¸µ(10-20ëŒ€) ì„ í˜¸ë„ ë†’ìŒ (+30%)
    # - ì§„í•œë§›/í”„ë¦¬ë¯¸ì—„: ìš”ë¦¬ì• í˜¸ê°€, ê³ ì†Œë“ì¸µ ì„ í˜¸ (+30%)
    if 'ë§¤ì½¤' in product_name:
        spicy_lover_mask = df['age'].isin(['10ëŒ€', '20ëŒ€'])
        weights[spicy_lover_mask] *= 1.3
        
    if 'ì§„' in product_name or 'í”„ë¦¬ë¯¸ì—„' in product_name:
        pro_cook_mask = df['lifestyle'].isin(['ìš”ë¦¬ì• í˜¸ê°€']) | df['income_level'].isin(['ì¤‘ìƒ', 'ìƒ'])
        weights[pro_cook_mask] *= 1.3
        
    # [ê°€ì„¤ 3] RTD ì»¤í”¼ ë§› ì„ í˜¸ë„
    # - ë°”ë‹ë¼ë¼ë–¼: ë‹¨ë§› ì„ í˜¸ ê²½í–¥ì´ ìˆëŠ” 10-20ëŒ€ ì„ í˜¸ (+15%)
    if 'ë°”ë‹ë¼ë¼ë–¼' in product_name:
        sweet_lover_mask = df['age'].isin(['10ëŒ€', '20ëŒ€'])
        weights[sweet_lover_mask] *= 1.15
        
    return weights

print("âœ… 3ë‹¨ê³„: [ê³ ë„í™”] ì œí’ˆ íŠ¹ì„±(ìš©ëŸ‰, ë§›)ì„ ë°˜ì˜í•œ ê°€ì¤‘ì¹˜ ë¶€ì—¬ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ==============================================================================
# ğŸ“ˆ 4ë‹¨ê³„ & 5ë‹¨ê³„: ì‹œë®¬ë ˆì´ì…˜ ë° ìµœì¢… íŒŒì¼ ìƒì„± (âœ¨ SKU ë‹¨ìœ„ë¡œ íŒŒë¼ë¯¸í„° ì„¸ë¶„í™”)
# ==============================================================================
# âœ¨ [í•µì‹¬ ìˆ˜ì •] ì œí’ˆêµ°ì´ ì•„ë‹Œ, ê°œë³„ ì œí’ˆ(SKU) ë‹¨ìœ„ë¡œ ì‹œì¥ ê·œëª¨(TAM)ì™€ ì ìœ ìœ¨(market_share)ì„ ì¬ì •ì˜
# Â  Â - ë™ì¼ ì œí’ˆêµ° ë‚´ì—ì„œ ìš©ëŸ‰/ë§›ì— ë”°ë¼ ì‹œì¥ ì ìœ ìœ¨ì„ ë¶„ë°° (í•©ê³„ëŠ” ê¸°ì¡´ê³¼ ìœ ì‚¬í•˜ê²Œ ì„¤ì •)
# Â  Â - ëª…ì ˆ ModifiersëŠ” ê´€ë ¨ ì œí’ˆêµ°(ë¦¬ì±”, ì°¸ì¹˜ì•¡)ì— ë™ì¼í•˜ê²Œ ì ìš©
HOLIDAY_MODIFIERS = {
    'seollal_chuseok': [1.8, 5.5, 1.0, 0.9, 1.0, 1.1, 1.2, 2.5, 6.5, 1.0, 1.0, 1.1],
    'seollal_chuseok_sub': [1.3, 3.0, 1.0, 1.1, 1.2, 1.1, 1.2, 1.8, 3.5, 1.1, 1.0, 1.3]
}
DEFAULT_MODIFIERS = [1.0] * 12

SIMULATION_PARAMS = {
    # í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸ (TAM: 60ë§Œ, ì ìœ ìœ¨: 0.1)
    'ë´ë§ˆí¬ í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸ 400g': {'tam': 600000, 'market_share': 0.05, 'modifiers': [1.2, 1.2, 1.2, 1.4, 1.4, 1.3, 1.2, 1.2, 0.9, 0.8, 0.7, 0.7]},
    
    # ë§›ì°¸ (TAM: 100ë§Œ, ì ìœ ìœ¨: 0.2) -> 4ê°œ ì œí’ˆì´ 0.2 ì ìœ ìœ¨ì„ ë‚˜ëˆ  ê°€ì§
    'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 135g': {'tam': 2000000, 'market_share': 0.07, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 90g':  {'tam': 2000000, 'market_share': 0.05, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 135g': {'tam': 2000000, 'market_share': 0.05, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 90g':  {'tam': 2000000, 'market_share': 0.03, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    
    # ë¦¬ì±” (TAM: 300ë§Œ, ì ìœ ìœ¨: 0.8) -> 2ê°œ ì œí’ˆì´ 0.8 ì ìœ ìœ¨ì„ ë‚˜ëˆ  ê°€ì§ (ëª…ì ˆ íŠ¹ìˆ˜ì„± ë°˜ì˜)
    'ë¦¬ì±” ì˜¤ë¯ˆë ›í–„ 200g': {'tam': 3000000, 'market_share': 0.3, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok']},
    'ë¦¬ì±” ì˜¤ë¯ˆë ›í–„ 340g': {'tam': 3000000, 'market_share': 0.5, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok']},

    # ì°¸ì¹˜ì•¡ (TAM: 25ë§Œ, ì ìœ ìœ¨: 0.125) -> 6ê°œ ì œí’ˆì´ 0.125 ì ìœ ìœ¨ì„ ë‚˜ëˆ  ê°€ì§ (ëª…ì ˆ íŠ¹ìˆ˜ì„± ë°˜ì˜)
    'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 500g':  {'tam': 250000, 'market_share': 0.025, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 900g':  {'tam': 250000, 'market_share': 0.020, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 500g':  {'tam': 250000, 'market_share': 0.030, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 900g':  {'tam': 250000, 'market_share': 0.025, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 500g': {'tam': 250000, 'market_share': 0.015, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 900g': {'tam': 250000, 'market_share': 0.010, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    
    # ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ  (TAM: 150ë§Œ, ì ìœ ìœ¨: 0.4) -> 2ê°œ ì œí’ˆì´ 0.4 ì ìœ ìœ¨ì„ ë‚˜ëˆ  ê°€ì§
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ë°”ë‹ë¼ë¼ë–¼ 250mL': {'tam': 2000000, 'market_share': 0.17, 'modifiers': [1.0, 1.1, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1, 1.1]},
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ì¹´í˜ë¼ë–¼ 250mL':   {'tam': 2000000, 'market_share': 0.23, 'modifiers': [1.0, 1.1, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1, 1.1]},
    
    'default': {'tam': 1000000, 'market_share': 0.10, 'modifiers': DEFAULT_MODIFIERS}
}
print("âœ… 4ë‹¨ê³„: [ì„¸ë¶„í™”] SKUë³„ ì‹œì¥ ì ìœ ìœ¨ ë° 'ëª…ì ˆ íŠ¹ìˆ˜ì„±'ì´ í¬í•¨ëœ ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„°ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

START_MONTH_INDEX = 6 # 7ì›”ì€ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¸ë±ìŠ¤ 6ì— í•´ë‹¹

for product, params in SIMULATION_PARAMS.items():
    original_modifiers = params['modifiers']
    # 7ì›”ë¶€í„° ëê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì•ìœ¼ë¡œ ê°€ì ¸ì˜¤ê³ , 1ì›”ë¶€í„° 6ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ë’¤ë¡œ ë¶™ì…ë‹ˆë‹¤.
    reordered_modifiers = original_modifiers[START_MONTH_INDEX:] + original_modifiers[:START_MONTH_INDEX]
    SIMULATION_PARAMS[product]['modifiers'] = reordered_modifiers
    # ì˜ˆ: [1,2,3,4,5,6,7,8,9,10,11,12] -> [7,8,9,10,11,12,1,2,3,4,5,6]

print("âœ… ëª¨ë“  ì œí’ˆì˜ ì›”ë³„ ê°€ì¤‘ì¹˜ ì¬ì •ë ¬ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
# ==============================================================================

# íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€í•˜ì—¬ ë²„ì „ ê´€ë¦¬
timestamp = time.strftime("%Y%m%d_%H%M%S")
submission_filename = os.path.join(PATH, f'my_submission_v2.1_{timestamp}.csv')

for index, row in submission_df.iterrows():
    product_name = row['product_name']
    
    params = SIMULATION_PARAMS.get(product_name, SIMULATION_PARAMS['default'])
    
    weights = get_weights_by_product(product_name, personas_df)

    monthly_sales = []
    num_personas = len(personas_df)
    for month_index in range(12):
        total_purchase_points = (
            personas_df['purchase_probability'] *
            personas_df['base_purchase_frequency_per_month'] *
            weights *
            params['modifiers'][month_index] # ì´ì œ params['modifiers'][0]ì€ 7ì›” ê°€ì¤‘ì¹˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
        ).sum()

        final_sales = (total_purchase_points / num_personas) * params['tam'] * params['market_share']
        monthly_sales.append(int(final_sales))

    submission_df.iloc[index, 1:] = monthly_sales

submission_df.to_csv(submission_filename, index=False)
print(f"\nâœ… 5ë‹¨ê³„: ìµœì¢… ì œì¶œ íŒŒì¼ '{submission_filename}' ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("\n[ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ (ìƒìœ„ 5ê°œ ì œí’ˆ) ]")
print(submission_df.head())